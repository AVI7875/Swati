{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NLP PRAC1,2,3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ScoPq9mJmmt"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import nltk.corpus\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiMru2sXMnz1",
        "outputId": "c55461dd-2427-4966-a102-46826ee926e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldkrTFCIVtrT",
        "outputId": "59b72f29-8d06-42ea-9c36-9d8c35626097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvY9PXB23rvb",
        "outputId": "c554e1de-ab3a-49cf-bd23-8a4165138271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "a-J3J5q6KcC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Sample = 'The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania'"
      ],
      "metadata": {
        "id": "GWQl8n5yKE2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply tokenization"
      ],
      "metadata": {
        "id": "AdssnNnDKa_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tokens = word_tokenize(Sample)\n",
        "sample_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ7dOp-TLva9",
        "outputId": "bf55a8e2-28c2-41cb-f984-6415e5ee4dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Toolkit',\n",
              " ',',\n",
              " 'or',\n",
              " 'more',\n",
              " 'commonly',\n",
              " 'NLTK',\n",
              " ',',\n",
              " 'is',\n",
              " 'a',\n",
              " 'suite',\n",
              " 'of',\n",
              " 'libraries',\n",
              " 'and',\n",
              " 'programs',\n",
              " 'for',\n",
              " 'symbolic',\n",
              " 'and',\n",
              " 'statistical',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'for',\n",
              " 'English',\n",
              " 'written',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Python',\n",
              " 'programming',\n",
              " 'language',\n",
              " '.',\n",
              " 'It',\n",
              " 'was',\n",
              " 'developed',\n",
              " 'by',\n",
              " 'Steven',\n",
              " 'Bird',\n",
              " 'and',\n",
              " 'Edward',\n",
              " 'Loper',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Department',\n",
              " 'of',\n",
              " 'Computer',\n",
              " 'and',\n",
              " 'Information',\n",
              " 'Science',\n",
              " 'at',\n",
              " 'the',\n",
              " 'University',\n",
              " 'of',\n",
              " 'Pennsylvania']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sample_tokens), len(sample_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-6QgMdTLvXW",
        "outputId": "0d951050-66e1-4462-f0f5-1b61376a164a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding frequency of words in data"
      ],
      "metadata": {
        "id": "39WtaYzmNrp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdisk = FreqDist()"
      ],
      "metadata": {
        "id": "g2LUCTzuNiK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sample_tokens:\n",
        "  fdisk[i] = fdisk[i] +1\n",
        "fdisk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfHcVbaIN7ni",
        "outputId": "8f52a51f-dfb9-4737-b5d4-0083cf6a6744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'(': 1,\n",
              "          ')': 1,\n",
              "          ',': 2,\n",
              "          '.': 1,\n",
              "          'Bird': 1,\n",
              "          'Computer': 1,\n",
              "          'Department': 1,\n",
              "          'Edward': 1,\n",
              "          'English': 1,\n",
              "          'Information': 1,\n",
              "          'It': 1,\n",
              "          'Language': 1,\n",
              "          'Loper': 1,\n",
              "          'NLP': 1,\n",
              "          'NLTK': 1,\n",
              "          'Natural': 1,\n",
              "          'Pennsylvania': 1,\n",
              "          'Python': 1,\n",
              "          'Science': 1,\n",
              "          'Steven': 1,\n",
              "          'The': 1,\n",
              "          'Toolkit': 1,\n",
              "          'University': 1,\n",
              "          'a': 1,\n",
              "          'and': 4,\n",
              "          'at': 1,\n",
              "          'by': 1,\n",
              "          'commonly': 1,\n",
              "          'developed': 1,\n",
              "          'for': 2,\n",
              "          'in': 2,\n",
              "          'is': 1,\n",
              "          'language': 2,\n",
              "          'libraries': 1,\n",
              "          'more': 1,\n",
              "          'natural': 1,\n",
              "          'of': 3,\n",
              "          'or': 1,\n",
              "          'processing': 1,\n",
              "          'programming': 1,\n",
              "          'programs': 1,\n",
              "          'statistical': 1,\n",
              "          'suite': 1,\n",
              "          'symbolic': 1,\n",
              "          'the': 3,\n",
              "          'was': 1,\n",
              "          'written': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_5 = fdisk.most_common(1)\n",
        "top_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4J-3hjsOGjs",
        "outputId": "9f302578-4873-401f-8604-3e489be9cce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('and', 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram, trigram and ngrams"
      ],
      "metadata": {
        "id": "kQAeCGxsRyCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.bigrams(sample_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZq38l7POPUM",
        "outputId": "85d3c0d2-6e90-45ca-a60f-285f8317d4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'Natural'),\n",
              " ('Natural', 'Language'),\n",
              " ('Language', 'Toolkit'),\n",
              " ('Toolkit', ','),\n",
              " (',', 'or'),\n",
              " ('or', 'more'),\n",
              " ('more', 'commonly'),\n",
              " ('commonly', 'NLTK'),\n",
              " ('NLTK', ','),\n",
              " (',', 'is'),\n",
              " ('is', 'a'),\n",
              " ('a', 'suite'),\n",
              " ('suite', 'of'),\n",
              " ('of', 'libraries'),\n",
              " ('libraries', 'and'),\n",
              " ('and', 'programs'),\n",
              " ('programs', 'for'),\n",
              " ('for', 'symbolic'),\n",
              " ('symbolic', 'and'),\n",
              " ('and', 'statistical'),\n",
              " ('statistical', 'natural'),\n",
              " ('natural', 'language'),\n",
              " ('language', 'processing'),\n",
              " ('processing', '('),\n",
              " ('(', 'NLP'),\n",
              " ('NLP', ')'),\n",
              " (')', 'for'),\n",
              " ('for', 'English'),\n",
              " ('English', 'written'),\n",
              " ('written', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'Python'),\n",
              " ('Python', 'programming'),\n",
              " ('programming', 'language'),\n",
              " ('language', '.'),\n",
              " ('.', 'It'),\n",
              " ('It', 'was'),\n",
              " ('was', 'developed'),\n",
              " ('developed', 'by'),\n",
              " ('by', 'Steven'),\n",
              " ('Steven', 'Bird'),\n",
              " ('Bird', 'and'),\n",
              " ('and', 'Edward'),\n",
              " ('Edward', 'Loper'),\n",
              " ('Loper', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'Department'),\n",
              " ('Department', 'of'),\n",
              " ('of', 'Computer'),\n",
              " ('Computer', 'and'),\n",
              " ('and', 'Information'),\n",
              " ('Information', 'Science'),\n",
              " ('Science', 'at'),\n",
              " ('at', 'the'),\n",
              " ('the', 'University'),\n",
              " ('University', 'of'),\n",
              " ('of', 'Pennsylvania')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.trigrams(sample_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2hzVyGdR-6U",
        "outputId": "0d2d7b2c-1afb-4683-88b2-603cbda9378f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'Natural', 'Language'),\n",
              " ('Natural', 'Language', 'Toolkit'),\n",
              " ('Language', 'Toolkit', ','),\n",
              " ('Toolkit', ',', 'or'),\n",
              " (',', 'or', 'more'),\n",
              " ('or', 'more', 'commonly'),\n",
              " ('more', 'commonly', 'NLTK'),\n",
              " ('commonly', 'NLTK', ','),\n",
              " ('NLTK', ',', 'is'),\n",
              " (',', 'is', 'a'),\n",
              " ('is', 'a', 'suite'),\n",
              " ('a', 'suite', 'of'),\n",
              " ('suite', 'of', 'libraries'),\n",
              " ('of', 'libraries', 'and'),\n",
              " ('libraries', 'and', 'programs'),\n",
              " ('and', 'programs', 'for'),\n",
              " ('programs', 'for', 'symbolic'),\n",
              " ('for', 'symbolic', 'and'),\n",
              " ('symbolic', 'and', 'statistical'),\n",
              " ('and', 'statistical', 'natural'),\n",
              " ('statistical', 'natural', 'language'),\n",
              " ('natural', 'language', 'processing'),\n",
              " ('language', 'processing', '('),\n",
              " ('processing', '(', 'NLP'),\n",
              " ('(', 'NLP', ')'),\n",
              " ('NLP', ')', 'for'),\n",
              " (')', 'for', 'English'),\n",
              " ('for', 'English', 'written'),\n",
              " ('English', 'written', 'in'),\n",
              " ('written', 'in', 'the'),\n",
              " ('in', 'the', 'Python'),\n",
              " ('the', 'Python', 'programming'),\n",
              " ('Python', 'programming', 'language'),\n",
              " ('programming', 'language', '.'),\n",
              " ('language', '.', 'It'),\n",
              " ('.', 'It', 'was'),\n",
              " ('It', 'was', 'developed'),\n",
              " ('was', 'developed', 'by'),\n",
              " ('developed', 'by', 'Steven'),\n",
              " ('by', 'Steven', 'Bird'),\n",
              " ('Steven', 'Bird', 'and'),\n",
              " ('Bird', 'and', 'Edward'),\n",
              " ('and', 'Edward', 'Loper'),\n",
              " ('Edward', 'Loper', 'in'),\n",
              " ('Loper', 'in', 'the'),\n",
              " ('in', 'the', 'Department'),\n",
              " ('the', 'Department', 'of'),\n",
              " ('Department', 'of', 'Computer'),\n",
              " ('of', 'Computer', 'and'),\n",
              " ('Computer', 'and', 'Information'),\n",
              " ('and', 'Information', 'Science'),\n",
              " ('Information', 'Science', 'at'),\n",
              " ('Science', 'at', 'the'),\n",
              " ('at', 'the', 'University'),\n",
              " ('the', 'University', 'of'),\n",
              " ('University', 'of', 'Pennsylvania')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.ngrams(sample_tokens,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gcOQBn8STTb",
        "outputId": "23d496f0-c339-420a-98a6-856dff309f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'Natural', 'Language', 'Toolkit', ',', 'or'),\n",
              " ('Natural', 'Language', 'Toolkit', ',', 'or', 'more'),\n",
              " ('Language', 'Toolkit', ',', 'or', 'more', 'commonly'),\n",
              " ('Toolkit', ',', 'or', 'more', 'commonly', 'NLTK'),\n",
              " (',', 'or', 'more', 'commonly', 'NLTK', ','),\n",
              " ('or', 'more', 'commonly', 'NLTK', ',', 'is'),\n",
              " ('more', 'commonly', 'NLTK', ',', 'is', 'a'),\n",
              " ('commonly', 'NLTK', ',', 'is', 'a', 'suite'),\n",
              " ('NLTK', ',', 'is', 'a', 'suite', 'of'),\n",
              " (',', 'is', 'a', 'suite', 'of', 'libraries'),\n",
              " ('is', 'a', 'suite', 'of', 'libraries', 'and'),\n",
              " ('a', 'suite', 'of', 'libraries', 'and', 'programs'),\n",
              " ('suite', 'of', 'libraries', 'and', 'programs', 'for'),\n",
              " ('of', 'libraries', 'and', 'programs', 'for', 'symbolic'),\n",
              " ('libraries', 'and', 'programs', 'for', 'symbolic', 'and'),\n",
              " ('and', 'programs', 'for', 'symbolic', 'and', 'statistical'),\n",
              " ('programs', 'for', 'symbolic', 'and', 'statistical', 'natural'),\n",
              " ('for', 'symbolic', 'and', 'statistical', 'natural', 'language'),\n",
              " ('symbolic', 'and', 'statistical', 'natural', 'language', 'processing'),\n",
              " ('and', 'statistical', 'natural', 'language', 'processing', '('),\n",
              " ('statistical', 'natural', 'language', 'processing', '(', 'NLP'),\n",
              " ('natural', 'language', 'processing', '(', 'NLP', ')'),\n",
              " ('language', 'processing', '(', 'NLP', ')', 'for'),\n",
              " ('processing', '(', 'NLP', ')', 'for', 'English'),\n",
              " ('(', 'NLP', ')', 'for', 'English', 'written'),\n",
              " ('NLP', ')', 'for', 'English', 'written', 'in'),\n",
              " (')', 'for', 'English', 'written', 'in', 'the'),\n",
              " ('for', 'English', 'written', 'in', 'the', 'Python'),\n",
              " ('English', 'written', 'in', 'the', 'Python', 'programming'),\n",
              " ('written', 'in', 'the', 'Python', 'programming', 'language'),\n",
              " ('in', 'the', 'Python', 'programming', 'language', '.'),\n",
              " ('the', 'Python', 'programming', 'language', '.', 'It'),\n",
              " ('Python', 'programming', 'language', '.', 'It', 'was'),\n",
              " ('programming', 'language', '.', 'It', 'was', 'developed'),\n",
              " ('language', '.', 'It', 'was', 'developed', 'by'),\n",
              " ('.', 'It', 'was', 'developed', 'by', 'Steven'),\n",
              " ('It', 'was', 'developed', 'by', 'Steven', 'Bird'),\n",
              " ('was', 'developed', 'by', 'Steven', 'Bird', 'and'),\n",
              " ('developed', 'by', 'Steven', 'Bird', 'and', 'Edward'),\n",
              " ('by', 'Steven', 'Bird', 'and', 'Edward', 'Loper'),\n",
              " ('Steven', 'Bird', 'and', 'Edward', 'Loper', 'in'),\n",
              " ('Bird', 'and', 'Edward', 'Loper', 'in', 'the'),\n",
              " ('and', 'Edward', 'Loper', 'in', 'the', 'Department'),\n",
              " ('Edward', 'Loper', 'in', 'the', 'Department', 'of'),\n",
              " ('Loper', 'in', 'the', 'Department', 'of', 'Computer'),\n",
              " ('in', 'the', 'Department', 'of', 'Computer', 'and'),\n",
              " ('the', 'Department', 'of', 'Computer', 'and', 'Information'),\n",
              " ('Department', 'of', 'Computer', 'and', 'Information', 'Science'),\n",
              " ('of', 'Computer', 'and', 'Information', 'Science', 'at'),\n",
              " ('Computer', 'and', 'Information', 'Science', 'at', 'the'),\n",
              " ('and', 'Information', 'Science', 'at', 'the', 'University'),\n",
              " ('Information', 'Science', 'at', 'the', 'University', 'of'),\n",
              " ('Science', 'at', 'the', 'University', 'of', 'Pennsylvania')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming and lemmatization"
      ],
      "metadata": {
        "id": "lbcNffNGSzhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()"
      ],
      "metadata": {
        "id": "l5g_GdGfSpu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pst.stem('helping'),pst.stem('Durga'),pst.stem('Aastha'),pst.stem('studies'),pst.stem('cops'),pst.stem('copies')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf3rBgLcUG_M",
        "outputId": "5f21b94e-3522-444a-ec35-5f0fd3b85bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('help', 'durga', 'aastha', 'studi', 'cop', 'copi')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemm = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "8R2rx9muUMXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemm.lemmatize('copies'), lemm.lemmatize('studies'),lemm.lemmatize('studeis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNoC8_qhVPrQ",
        "outputId": "4b4ee699-48f4-4f2a-c54a-99f016d64fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('copy', 'study', 'studeis')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " mystring = \"Hi, My name is Durga. I am studing M.Sc.Computer Science\""
      ],
      "metadata": {
        "id": "FVTNYGWT2r4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mytokens = word_tokenize(mystring)"
      ],
      "metadata": {
        "id": "jKcsmrkd23fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in mytokens:\n",
        "  print(nltk.pos_tag([i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh7EsHkS3QEo",
        "outputId": "5d41fb03-8309-49ee-9508-ce8559ab0ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hi', 'NN')]\n",
            "[(',', ',')]\n",
            "[('My', 'PRP$')]\n",
            "[('name', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('Durga', 'NN')]\n",
            "[('.', '.')]\n",
            "[('I', 'PRP')]\n",
            "[('am', 'VBP')]\n",
            "[('studing', 'VBG')]\n",
            "[('M.Sc.Computer', 'NN')]\n",
            "[('Science', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply named entity recognition"
      ],
      "metadata": {
        "id": "8ZPZWTmy4ZcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "String = \"I live in Mumbai with my Family.\""
      ],
      "metadata": {
        "id": "WBZkH8Nw4dAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mystr = word_tokenize(String)\n",
        "mystr\n",
        "\n",
        "str_tag = nltk.pos_tag(mystr)\n",
        "\n",
        "for i in mystr:\n",
        "  print(nltk.pos_tag(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdJTU6IR48Ix",
        "outputId": "f8b85bf2-face-4988-9ba8-5b8bfd4dfc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRP')]\n",
            "[('l', 'NN'), ('i', 'NN'), ('v', 'VBP'), ('e', 'NN')]\n",
            "[('i', 'NN'), ('n', 'VBP')]\n",
            "[('M', 'NNP'), ('u', 'JJ'), ('m', 'NN'), ('b', 'IN'), ('a', 'DT'), ('i', 'NN')]\n",
            "[('w', 'NN'), ('i', 'NN'), ('t', 'VBP'), ('h', 'NN')]\n",
            "[('m', 'NN'), ('y', 'NN')]\n",
            "[('F', 'NNP'), ('a', 'DT'), ('m', 'NN'), ('i', 'NN'), ('l', 'VBP'), ('y', 'NN')]\n",
            "[('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.chunk import ne_chunk\n",
        "nltk.download('words')\n",
        "NET =  ne_chunk(str_tag)\n",
        "print(NET)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxxyNHYH6-ec",
        "outputId": "58056f50-b822-4a93-98c3-cb8643ecf5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "(S\n",
            "  I/PRP\n",
            "  live/VBP\n",
            "  in/IN\n",
            "  (GPE Mumbai/NNP)\n",
            "  with/IN\n",
            "  my/PRP$\n",
            "  Family/NNP\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "String_1 = \"This is my NLP Practical\""
      ],
      "metadata": {
        "id": "ioM5iw0j8N2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "String_1_token = word_tokenize(String_1)\n",
        "String1_tags = nltk.pos_tag(String_1_token)\n",
        "String1_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXNhyNH59S2T",
        "outputId": "8761c61e-5a04-42ee-a725-1def793f2e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('my', 'PRP$'),\n",
              " ('NLP', 'JJ'),\n",
              " ('Practical', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string1_ner = ne_chunk(String1_tags)\n",
        "print(string1_ner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fj3d76c-Rlr",
        "outputId": "2d7fa2d5-daf6-4dfb-b5d3-69bb409b3483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S This/DT is/VBZ my/PRP$ (ORGANIZATION NLP/JJ Practical/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "ccSHJhyo-an6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I am using python programming language for this practical\")"
      ],
      "metadata": {
        "id": "bFk0q_dx-c6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig67fGqT-nR9",
        "outputId": "64f8b9a5-46c3-465f-e68b-7c0c09c2c845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "am\n",
            "using\n",
            "python\n",
            "programming\n",
            "language\n",
            "for\n",
            "this\n",
            "practical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token= doc[2]\n",
        "token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXgaGECpA2r4",
        "outputId": "fb35afd7-82e8-4ca6-90c9-497136c02364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "using"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "span = doc[2:6]\n",
        "span"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99y_3pmjBF-N",
        "outputId": "503efc9b-e296-4fa5-f876-c31ab5a77f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "using python programming language"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I am studing Tokenization\")\n",
        "for token in doc:\n",
        "  print(token.i,token.text,token.pos_)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkgVbCC9BT2A",
        "outputId": "abfdd85e-07f8-49be-abe5-428626b0bf14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 I PRON\n",
            "1 am AUX\n",
            "2 studing VERB\n",
            "3 Tokenization NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I don't like to cook.\")"
      ],
      "metadata": {
        "id": "OSgM19lJB9np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "q56x4HndCQbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher"
      ],
      "metadata": {
        "id": "Kea5zTeaCus_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"India is developing country\")\n",
        "\n",
        "pattern = [{'LEMMA': 'develop'}, {'ORTH': 'country'}]\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add('white_Pattern', None, pattern)\n",
        "matches = matcher(doc)\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AGeiOTbDKi6",
        "outputId": "bf61f0a8-52c9-4a8e-a5fb-e3c41cc86bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(4191279314630736679, 2, 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id, start, end in matches:\n",
        "  matched_span = doc[start:end]\n",
        "  print(matched_span.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM4Ib6GYDOyY",
        "outputId": "3f3a834c-48ee-4a39-80bf-bbc772101fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "developing country\n"
          ]
        }
      ]
    }
  ]
}